{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWGVJ1JLyFmO"
      },
      "source": [
        "In this basic functionalities of [PyTorch](https://pytorch.org) will be explored for small datasets. The goal is to work on how to load images, pre-process the images and perform data augmentation. Finally, a deep neural network will be trained to perform image classification.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KbnvxJGyFmQ"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "2Hm7_ImKyFmR"
      },
      "source": [
        "In this task, the data will be loaded in two different way. At first, the `torchvision.datasets` subclasses will be used to load a dataset. Second, we will write are own dataset loader that performs the same activity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzdc_DWRyFmT"
      },
      "source": [
        "### a) Built-in Torch Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I-v9GxvRyFmV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soobFMPbyFmb"
      },
      "outputs": [],
      "source": [
        "\n",
        "FashionMNIST_dataset = torchvision.datasets.FashionMNIST(root=\"./data\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "MNIST_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "# Dataloader MNIST\n",
        "MNIST_dataloader = DataLoader(MNIST_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "\n",
        "# Dataloader Fashion-MNIST\n",
        "FashionMNIST_dataloader = DataLoader(FashionMNIST_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUs30kFuyFmc"
      },
      "outputs": [],
      "source": [
        "# Visualize MNIST images\n",
        "\n",
        "for images, labels in MNIST_dataloader:\n",
        "    figs, axis = plt.subplots(1,3, figsize=(9,9))\n",
        "    for i, image in enumerate(images[:3]):\n",
        "        axis[i].imshow(image.numpy().transpose(1,2,0))\n",
        "        axis[i].set_title(MNIST_dataset.classes[labels[i]])\n",
        "        axis[i].axis('off')\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS3GnVnVyFme"
      },
      "outputs": [],
      "source": [
        "# Visualize Fashion MNIST images\n",
        "for images, labels in FashionMNIST_dataloader:\n",
        "    figures, axss = plt.subplots(1,3, figsize = (9,9))\n",
        "    for i, image in enumerate(images[:3]):\n",
        "        axss[i].imshow(image.numpy().transpose(1,2,0))\n",
        "        axss[i].set_title(FashionMNIST_dataset.classes[labels[i]])\n",
        "        axss[i].axis(\"off\")\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_kTHDF8yFmf"
      },
      "source": [
        "### b) Customized Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypHzywfPyFmh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import urllib.request\n",
        "import gzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": true,
        "id": "IKDMH3v3yFmi"
      },
      "outputs": [],
      "source": [
        "class CustomClassification(Dataset):\n",
        "    def __init__(self, root_dir, train=True, transform=None, url_input=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.url_input = url_input\n",
        "\n",
        "        if self.train:\n",
        "            self.data_file = 'train-images-idx3-ubyte.gz'\n",
        "            self.label_file = 'train-labels-idx1-ubyte.gz'\n",
        "        else:\n",
        "            self.data_file = 't10k-images-idx3-ubyte.gz'\n",
        "            self.label_file = 't10k-labels-idx1-ubyte.gz'\n",
        "\n",
        "        self.data_path = os.path.join(self.root_dir, self.data_file)\n",
        "        self.label_path = os.path.join(self.root_dir, self.label_file)\n",
        "\n",
        "        if not os.path.exists(self.data_path) or not os.path.exists(self.label_path):\n",
        "            print(\"Downloading dataset...\")\n",
        "            os.makedirs(self.root_dir, exist_ok=True)\n",
        "            self.download_dataset()\n",
        "\n",
        "        with gzip.open(self.label_path, 'rb') as f:\n",
        "            magic_num, num_labels = np.frombuffer(f.read(8), dtype=np.int32)\n",
        "            self.labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "\n",
        "\n",
        "        if self.train:\n",
        "            with gzip.open(self.data_path, 'rb') as f:\n",
        "                magic_num, num_images, num_rows, num_cols = np.frombuffer(f.read(16), dtype=np.int32)\n",
        "                self.data = np.frombuffer(f.read(), dtype=np.uint8).reshape(60000, 28, 28)\n",
        "\n",
        "        if self.train==False :\n",
        "            with gzip.open(self.data_path, 'rb') as f:\n",
        "                magic_num, num_images, num_rows, num_cols = np.frombuffer(f.read(16), dtype=np.int32)\n",
        "                self.data = np.frombuffer(f.read(), dtype=np.uint8).reshape(10000, 28, 28)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def download_dataset(self):\n",
        "        url = self.url_input\n",
        "        files = [self.data_file, self.label_file]\n",
        "\n",
        "        for file in files:\n",
        "            file_url = url + file\n",
        "            file_path = os.path.join(self.root_dir, file)\n",
        "\n",
        "            urllib.request.urlretrieve(file_url, file_path)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load MNIST using custom dataset loader\n",
        "\n",
        "mnist_dataset_custom = CustomClassification(root_dir='./data/mnist', train=True, transform=transforms.ToTensor(), url_input= 'http://yann.lecun.com/exdb/mnist/')\n",
        "mnist_dataloader_custom = DataLoader(mnist_dataset_custom, batch_size=32, shuffle=True)\n",
        "\n",
        "# Visualize CUSTOM MNIST images\n",
        "\n",
        "for images, labels in mnist_dataloader_custom:\n",
        "    figures, axss = plt.subplots(1,8, figsize = (9,9))\n",
        "    for i, image in enumerate(images[:8]):\n",
        "        axss[i].imshow(image.numpy().transpose(1,2,0))\n",
        "        axss[i].set_title(MNIST_dataset.classes[labels[i]])\n",
        "        axss[i].axis(\"off\")\n",
        "    plt.show()\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MNp1D13yFml"
      },
      "outputs": [],
      "source": [
        "# Load CUSTOM Fashion MNIST using custom dataset loader\n",
        "\n",
        "Fmnist_dataset_custom = CustomClassification(root_dir='./data/FashionMNIST', train=True, transform=transforms.ToTensor(), url_input='http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/')\n",
        "Fmnist_dataloader_custom = DataLoader(Fmnist_dataset_custom, batch_size=32, shuffle=True)\n",
        "\n",
        "# Visualize CUSTOM MNIST images\n",
        "\n",
        "for images, labels in Fmnist_dataloader_custom:\n",
        "    figures, axss = plt.subplots(1,8, figsize = (9,9))\n",
        "    for i, image in enumerate(images[:8]):\n",
        "        axss[i].imshow(image.numpy().transpose(1,2,0))\n",
        "        axss[i].set_title(FashionMNIST_dataset.classes[labels[i]])\n",
        "        axss[i].axis(\"off\")\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzsLLHsxyFmm"
      },
      "source": [
        "## 2. Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ospA6TZwyFmn"
      },
      "source": [
        "In this task, the [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset will be employed for learning a classifier. The classifier will be a convolutional neural network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eeVeLfMyFmn"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the CNN model\n",
        "class CNN_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Set device (CPU or GPU)\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define funtion to Train the model,\n",
        "# Here output of this function will be the loss and accuracy history of train and test data\n",
        "def train_evaluate_model(model, train_dataloader, train_dataset, test_dataloader, test_dataset, num_epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        for images, labels in train_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "        train_accuracy = 100 * train_correct / train_total\n",
        "        train_losses.append(train_loss / len(train_dataset))\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        test_loss = 0\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_dataloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "            test_accuracy = 100 * test_correct / test_total\n",
        "            test_accuracies.append(test_accuracy)\n",
        "            test_losses.append((test_loss) / (len(test_dataset)))\n",
        "        print(\"\\nEpoch:\",epoch,\" completed. Train accuracy:\",train_accuracies[epoch],\", Train loss\", train_losses[epoch])\n",
        "        print(\"Test accuracy:\", test_accuracies[epoch], \", Test loss:\", test_losses[epoch])\n",
        "    return train_accuracies, train_losses, test_accuracies, test_losses\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZx8d6WLyFmp"
      },
      "outputs": [],
      "source": [
        "# Load FashionMNIST dataset (Train and Test) using CUSTOM dataset loader\n",
        "fashion_mnist_dataset = CustomClassification(root_dir='./data/fashion-mnist', train=True, transform=transforms.ToTensor(), url_input='http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/')\n",
        "fashion_mnist_test_dataset = CustomClassification(root_dir='./data/fashion-mnist', train=False, transform=transforms.ToTensor(), url_input='http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/')\n",
        "\n",
        "fashion_mnist_dataloader = DataLoader(fashion_mnist_dataset, batch_size=32, shuffle=True)\n",
        "fashion_mnist_test_dataloader = DataLoader(fashion_mnist_test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the CNN model\n",
        "CNNmodel_FashionMNIST = CNN_model().to(device)\n",
        "\n",
        "num_epochs=10\n",
        "train_accuracies_FashionMNIST, train_losses_FashionMNIST, test_accuracies_FashionMNIST, test_losses_FashionMNIST = train_evaluate_model(CNNmodel_FashionMNIST,\n",
        "                                                                                                                                        fashion_mnist_dataloader,\n",
        "                                                                                                                                        fashion_mnist_dataset,\n",
        "                                                                                                                                        fashion_mnist_test_dataloader,\n",
        "                                                                                                                                        fashion_mnist_test_dataset, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pduBuLyZyFmq"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(0,num_epochs), train_accuracies_FashionMNIST, \"r\", label=\"Training Accuracy\")\n",
        "plt.plot(np.arange(0,num_epochs), test_accuracies_FashionMNIST, \"b\", label=\"Test Accuracy\")\n",
        "plt.title(\"Training and Test Accuracies - Fashion MNIST -without Data Augmentation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I27rLl-GyFmq"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(0,num_epochs), train_losses_FashionMNIST, \"r\",  label=\"Training Loss\")\n",
        "plt.plot(np.arange(0,num_epochs), test_losses_FashionMNIST, \"b\",  label=\"Test Loss\")\n",
        "plt.title(\"Training and Test Losses - Fashion MNIST -without Data Augmentation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss/ Error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s4zWTU1yFmr"
      },
      "outputs": [],
      "source": [
        "print(\"The train accuracy after 10 epochs of FashionMNIST dataset without augmentation:\", train_accuracies_FashionMNIST[9])\n",
        "print(\"The train loss after 10 epochs of FashionMNIST dataset without augmentation:\", train_losses_FashionMNIST[9])\n",
        "print(\"The final test accuracy of FashionMNIST dataset without augmentation:\", test_accuracies_FashionMNIST[9])\n",
        "print(\"The final test loss of FashionMNIST dataset without augmentation:\", test_losses_FashionMNIST[9])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odLBMOoCyFms"
      },
      "source": [
        "## 3. Data Augmentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBF7ysC9yFmt"
      },
      "source": [
        "The datasets [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) and [MNIST](http://yann.lecun.com/exdb/mnist/) will be the testbed to investigate the impact of data augmentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "010OTBNZyFmu"
      },
      "outputs": [],
      "source": [
        "print(\"The train accuracy after 10 epochs of FashionMNIST dataset without augmentation:\", train_accuracies_FashionMNIST[9])\n",
        "print(\"The train loss after 10 epochs of FashionMNIST dataset without augmentation:\", train_losses_FashionMNIST[9])\n",
        "print(\"The final test accuracy of FashionMNIST dataset without augmentation:\", test_accuracies_FashionMNIST[9])\n",
        "print(\"The final test loss of FashionMNIST dataset without augmentation:\", test_losses_FashionMNIST[9])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqeXQTkZyFmv"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset using CUSTOM dataset loader\n",
        "mnist_dataset = CustomClassification(root_dir='./data/mnist', train=True, transform=transforms.ToTensor(), url_input='http://yann.lecun.com/exdb/mnist/')\n",
        "mnist_test_dataset = CustomClassification(root_dir='./data/mnist', train=False, transform=transforms.ToTensor(), url_input='http://yann.lecun.com/exdb/mnist/')\n",
        "\n",
        "mnist_dataloader = DataLoader(fashion_mnist_dataset, batch_size=32, shuffle=True)\n",
        "mnist_test_dataloader = DataLoader(fashion_mnist_test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the CNN model\n",
        "CNNmodel_MNIST = CNN_model().to(device)\n",
        "\n",
        "num_epochs=10\n",
        "train_accuracies_MNIST, train_losses_MNIST, test_accuracies_MNIST, test_losses_MNIST = train_evaluate_model(CNNmodel_MNIST, mnist_dataloader,\n",
        "                                                                                                            mnist_dataset, mnist_test_dataloader,\n",
        "                                                                                                            mnist_test_dataset, num_epochs)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WKZ4JztyFmv"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(0,num_epochs), train_accuracies_MNIST, \"r\", label=\"Training Accuracy\")\n",
        "plt.plot(np.arange(0,num_epochs), test_accuracies_MNIST, \"b\", label=\"Test Accuracy\")\n",
        "plt.title(\"Training and Test Accuracies - MNIST without Data augmentation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaeteQrbyFmw"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(0,num_epochs), train_losses_MNIST, \"r\",  label=\"Training Loss\")\n",
        "plt.plot(np.arange(0,num_epochs), test_losses_MNIST, \"b\",  label=\"Test Loss\")\n",
        "plt.title(\"Training and Test Losses - MNIST without Data augmentation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss/ Error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz1SMNhTyFmx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define the data transforms for data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(28, padding=5),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset with data augmentation\n",
        "mnist_dataset_dataAug = torchvision.datasets.MNIST(root='./data', train=True, download=False, transform=transform_train)\n",
        "mnist_dataset_test_dataAug = torchvision.datasets.MNIST(root='./data', train=False, download=False, transform=transform_test)\n",
        "\n",
        "# Create data loaders\n",
        "mnist_dataloader_dataAug = torch.utils.data.DataLoader(mnist_dataset_dataAug, batch_size=32, shuffle=True)\n",
        "mnist_dataloader_test_dataAug = torch.utils.data.DataLoader(mnist_dataset_test_dataAug, batch_size=32, shuffle=False)\n",
        "\n",
        "for images, labels in mnist_dataloader_dataAug:\n",
        "    figures, axss = plt.subplots(1,8, figsize = (9,9))\n",
        "    for i, image in enumerate(images[:8]):\n",
        "        axss[i].imshow(image.numpy().transpose(1,2,0))\n",
        "        axss[i].set_title(MNIST_dataset.classes[labels[i]])\n",
        "        axss[i].axis(\"off\")\n",
        "    plt.show()\n",
        "    break\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhQo0FSHyFmx"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "CNNmodel_MNIST_data_aug = CNN_model().to(device)\n",
        "\n",
        "num_epochs=10\n",
        "train_accuracies_MNIST_dataAug, train_losses_MNIST_dataAug, test_accuracies_MNIST_dataAug, test_losses_MNIST_dataAug = train_evaluate_model(CNNmodel_MNIST_data_aug, mnist_dataloader_dataAug,\n",
        "                                                                                                            mnist_dataset_dataAug, mnist_dataloader_test_dataAug,\n",
        "                                                                                                            mnist_dataset_test_dataAug, num_epochs)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ttjmf8CyFmy"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(0,num_epochs), train_accuracies_MNIST_dataAug, \"r\", label=\"Training Accuracy\")\n",
        "plt.plot(np.arange(0,num_epochs), test_accuracies_MNIST_dataAug, \"b\", label=\"Test Accuracy\")\n",
        "plt.title(\"Training and Test Accuracies - MNIST with DATA augmentation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk2DhkNHyFmz"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(0,num_epochs), train_losses_MNIST_dataAug, \"r\",  label=\"Training Loss\")\n",
        "plt.plot(np.arange(0,num_epochs), test_losses_MNIST_dataAug, \"b\",  label=\"Test Loss\")\n",
        "plt.title(\"Training and Test Losses - MNIST  with DATA augmentation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss/ Error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLv6NK5PyFmz"
      },
      "outputs": [],
      "source": [
        "# Load the FashionMNIST dataset with data augmentation\n",
        "Fashion_dataset_dataAug = torchvision.datasets.FashionMNIST(root='./data', train=True, download=False, transform=transform_train)\n",
        "Fashion_dataset_test_dataAug = torchvision.datasets.FashionMNIST(root='./data', train=False, download=False, transform=transform_test)\n",
        "\n",
        "# Create data loaders\n",
        "Fashion_dataloader_dataAug = torch.utils.data.DataLoader(Fashion_dataset_dataAug, batch_size=32, shuffle=True)\n",
        "Fashion_dataloader_test_dataAug = torch.utils.data.DataLoader(Fashion_dataset_test_dataAug, batch_size=32, shuffle=False)\n",
        "\n",
        "for images, labels in Fashion_dataloader_dataAug:\n",
        "    print(images.shape)\n",
        "    figures, axss = plt.subplots(1,8, figsize = (9,9))\n",
        "    for i, image in enumerate(images[:8]):\n",
        "        axss[i].imshow(image.numpy().transpose(1,2,0))\n",
        "        axss[i].set_title(FashionMNIST_dataset.classes[labels[i]])\n",
        "        axss[i].axis(\"off\")\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eojYWY0WyFm0"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "CNNmodel_FashionMNIST_data_aug = CNN_model().to(device)\n",
        "\n",
        "num_epochs=10\n",
        "train_accuracies_Fashion_dataAug, train_losses_Fashion_dataAug, test_accuracies_Fashion_dataAug, test_losses_Fashion_dataAug = train_evaluate_model(CNNmodel_FashionMNIST_data_aug, Fashion_dataloader_dataAug,\n",
        "                                                                                                            Fashion_dataset_dataAug, Fashion_dataloader_test_dataAug,\n",
        "                                                                                                            Fashion_dataset_test_dataAug, num_epochs)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ0rfmrxyFm1"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(0,num_epochs), train_accuracies_Fashion_dataAug, \"r\", label=\"Training Accuracy\")\n",
        "plt.plot(np.arange(0,num_epochs), test_accuracies_Fashion_dataAug, \"b\", label=\"Test Accuracy\")\n",
        "plt.title(\"Training and Test Accuracies - Fashion MNIST with DATA augmentation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leOOPX-RyFm1"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(0,num_epochs), train_losses_Fashion_dataAug, \"r\",  label=\"Training Loss\")\n",
        "plt.plot(np.arange(0,num_epochs), test_losses_Fashion_dataAug, \"b\",  label=\"Test Loss\")\n",
        "plt.title(\"Training and Test Losses - Fashion MNIST  with DATA augmentation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss/ Error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5mw46o6yFm2"
      },
      "outputs": [],
      "source": [
        "print(\"The train accuracy of MNIST dataset without augmentation:\", train_accuracies_MNIST[9])\n",
        "print(\"The test accuracy of MNIST dataset without augmentation:\", test_accuracies_MNIST[9])\n",
        "\n",
        "print(\"\\nThe train accuracy of MNIST dataset WITH DATA augmentation:\", train_accuracies_MNIST_dataAug[9])\n",
        "print(\"The test accuracy of MNIST dataset WITH DATA augmentation:\", test_accuracies_MNIST_dataAug[9])\n",
        "\n",
        "print(\"\\nThe train accuracy of FASHION MNIST dataset without augmentation:\", train_accuracies_FashionMNIST[9])\n",
        "print(\"The test accuracy of FASHION MNIST dataset without augmentation:\", test_accuracies_FashionMNIST[9])\n",
        "\n",
        "print(\"\\nThe train accuracy of FASHION MNIST dataset WITH DATA augmentation:\", train_accuracies_Fashion_dataAug[9])\n",
        "print(\"The test accuracy of FASHION MNIST dataset WITH DATA augmentation:\", test_accuracies_Fashion_dataAug[9])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}